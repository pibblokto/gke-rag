apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: {{ .Values.modelName }}
  namespace: using-system-models
  annotations:
    serving.kserve.io/autoscalerClass: keda
spec:
  predictor:
    model:
      env:
      - name: KSERVE_OPENAI_ROUTE_PREFIX
        value: ""
      modelFormat:
        name: huggingface
      args:
        - --model_name={{ .Values.modelName }}
        - --backend=huggingface
        - --task=text_embedding
      storageUri: hf://BAAI/{{ .Values.modelName }}
      resources:
        requests:
          cpu: "2"
          memory: 12Gi
        limits:
          cpu: "4"
          memory: 24Gi
    minReplicas: 1
    maxReplicas: 2
    autoScaling:
      metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: "Utilization"
            averageUtilization: 80
